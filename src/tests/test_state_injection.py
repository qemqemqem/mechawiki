#!/usr/bin/env python3
"""Simple test to verify state injection with LangGraph + MCP works."""

import asyncio
import toml
from typing import Dict, Any, Optional, List, TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage
from langchain_core.tools import BaseTool
from langchain_core.runnables import RunnableConfig
from langchain_mcp_adapters.client import MultiServerMCPClient
from fastmcp import FastMCP

# Load config
config = toml.load("config.toml")

# Define simple state schema
class TestState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    story_position: int  # Track position in story

# Create a minimal MCP server for testing
def create_test_mcp_server():
    """Create a minimal MCP server with advance tool."""
    mcp = FastMCP("TestAgent")
    
    @mcp.tool()
    def advance(
        num_words: Optional[int] = None,
        current_position: int = 0
    ) -> Dict[str, Any]:
        """Test advance function that accepts explicit position."""
        if num_words is None:
            num_words = 100
        
        new_position = current_position + num_words
        print(f"üêõ MCP advance() called: pos {current_position} -> {new_position}")
        
        return {
            "position": new_position,
            "content": f"Advanced from {current_position} to {new_position} words"
        }
    
    return mcp

# Mock LLM that always calls the advance tool
class MockLLM:
    """Mock LLM that simulates tool calling."""
    
    def __init__(self, tools):
        self.tools = {tool.name: tool for tool in tools}
        self.call_count = 0
    
    def bind_tools(self, tools):
        """Return self since we're already bound."""
        return self
    
    def invoke(self, messages, config=None):
        """Mock invoke that calls advance tool then stops."""
        self.call_count += 1
        
        if self.call_count == 1:
            # First call: call advance tool
            return AIMessage(
                content="I'll advance through the story",
                tool_calls=[{
                    "name": "advance", 
                    "args": {"num_words": 50},
                    "id": "call_1"
                }]
            )
        else:
            # Second call: finish
            return AIMessage(content="Done! Position updated successfully.")

async def test_state_injection():
    """Test that state injection works with MCP tools."""
    print("üß™ Testing LangGraph + MCP state injection...")
    
    # Setup MCP client using our existing minimal tools
    mcp_client = MultiServerMCPClient({
        "test_tools": {
            "command": ".venv/bin/python",
            "args": ["src/tools_minimal.py"],
            "transport": "stdio",
            "env": {}
        }
    })
    
    try:
        # Get tools from MCP server
        tools = await mcp_client.get_tools()
        print(f"‚úÖ Got {len(tools)} tools from MCP server")
        
        # Create mock LLM
        llm = MockLLM(tools)
        
        # Define graph nodes
        def call_model(state: TestState, config: RunnableConfig):
            """Call mock LLM."""
            messages = state["messages"]
            response = llm.invoke(messages, config=config)
            return {"messages": [response]}
        
        def should_continue(state: TestState):
            """Check if we should continue or call tools."""
            last_message = state["messages"][-1]
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"
            return END
        
        async def call_tools(state: TestState, config: RunnableConfig):
            """Custom tool node that properly handles MCP tools with state injection."""
            last_message = state["messages"][-1]
            tool_messages = []
            state_updates = {}
            
            print(f"üîß Calling tools from message: {last_message}")
            
            for tool_call in last_message.tool_calls:
                tool_name = tool_call["name"]
                print(f"üîß Tool call: {tool_name}")
                
                if tool_name == "advance":
                    # INJECT POSITION FROM STATE - this is our workaround for InjectedState
                    args = tool_call["args"].copy()
                    current_position = state.get("story_position", 0)
                    
                    print(f"üîß Injecting position {current_position} into advance call")
                    
                    # Import and call the internal implementation directly with injected position
                    import sys
                    sys.path.append('src')
                    from tools_minimal import _advance_impl
                    
                    result = _advance_impl(
                        num_words=args.get("num_words"),
                        current_position=current_position
                    )
                    
                    # Convert to JSON string to match MCP behavior
                    import json
                    result = json.dumps(result)
                    
                    print(f"üîß MCP tool result: {result}")
                    print(f"üîß Result type: {type(result)}")
                    
                    # Handle result - MCP tools might return JSON strings instead of dicts
                    if isinstance(result, str):
                        # Try to parse JSON string
                        try:
                            import json
                            parsed_result = json.loads(result)
                            print(f"üîß Parsed JSON result: {parsed_result}")
                            
                            # Extract data from parsed result
                            content = parsed_result.get("content", str(result))
                            new_position = parsed_result.get("position", current_position)
                            state_updates["story_position"] = new_position
                            print(f"üîß Extracting state update from JSON: position {current_position} -> {new_position}")
                            
                        except json.JSONDecodeError:
                            # Not JSON, use as-is
                            content = result
                            print(f"üîß Not JSON, using as-is: {result}")
                    
                    elif isinstance(result, dict):
                        # Already a dict
                        content = result.get("content", str(result))
                        new_position = result.get("position", current_position)
                        state_updates["story_position"] = new_position
                        print(f"üîß Extracting state update from dict: position {current_position} -> {new_position}")
                    
                    else:
                        # Other type, convert to string
                        content = str(result)
                        print(f"üîß Other result type {type(result)}, using as string")
                    
                    tool_messages.append(ToolMessage(
                        content=content,
                        tool_call_id=tool_call["id"]
                    ))
                else:
                    # Other tools - handle normally
                    tool = next(t for t in tools if t.name == tool_name)
                    result = await tool.ainvoke(tool_call["args"], config=config)
                    tool_messages.append(ToolMessage(
                        content=str(result),
                        tool_call_id=tool_call["id"]
                    ))
            
            print(f"üîß Final state updates being returned: {state_updates}")
            return {"messages": tool_messages, **state_updates}
        
        # Build graph
        workflow = StateGraph(TestState)
        workflow.add_node("agent", call_model)
        workflow.add_node("tools", call_tools)
        
        workflow.set_entry_point("agent")
        workflow.add_conditional_edges("agent", should_continue, {"tools": "tools", END: END})
        workflow.add_edge("tools", "agent")
        
        # Compile with memory
        checkpointer = InMemorySaver()
        graph = workflow.compile(checkpointer=checkpointer)
        
        # Test execution
        initial_state = {
            "messages": [HumanMessage(content="Please advance through the story")],
            "story_position": 0
        }
        
        config = {"configurable": {"thread_id": "test_1"}}
        
        print("üöÄ Running graph...")
        result = await graph.ainvoke(initial_state, config=config)
        
        print("‚úÖ Test completed!")
        print(f"Final state: {result}")
        print(f"Final position: {result.get('story_position', 'NOT_SET')}")
        
        # Verify position was updated
        if result.get('story_position') == 50:
            print("üéâ SUCCESS: State injection works! Position updated from 0 to 50")
        else:
            print(f"‚ùå FAILED: Expected position 50, got {result.get('story_position')}")
        
    finally:
        # Clean up (no close method needed)
        pass

if __name__ == "__main__":
    asyncio.run(test_state_injection())